<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Slab-Wise Aggregation of SoilProfileCollection Objects</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for slab-methods {aqp}"><tr><td>slab-methods {aqp}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Slab-Wise Aggregation of SoilProfileCollection Objects</h2>

<h3>Description</h3>

<p>Aggregate soil properties along user-defined 'slabs', and optionally within groups.</p>


<h3>Usage</h3>

<pre>
# method for SoilProfileCollection objects
slab(object, fm, slab.structure=1, strict=FALSE, 
slab.fun=.slab.fun.numeric.default, cpm=1, weights=NULL, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
<p>a SoilProfileCollection</p>
</td></tr>
<tr valign="top"><td><code>fm</code></td>
<td>
<p>A formula: either &lsquo;groups ~ var1 + var2 + var3&rsquo; where named variables are aggregated within &lsquo;groups&rsquo; OR where named variables are aggregated across the entire collection &lsquo; ~ var1 + var2 + var3&rsquo;. If 'groups' is a factor it must not contain NA.</p>
</td></tr>
<tr valign="top"><td><code>slab.structure</code></td>
<td>
<p>A user-defined slab thickness (defined by an integer), or user-defined structure (numeric vector). See details below.</p>
</td></tr>
<tr valign="top"><td><code>strict</code></td>
<td>
<p>logical: should horizons be strictly checked for self-consistency?</p>
</td></tr>
<tr valign="top"><td><code>slab.fun</code></td>
<td>
<p>Function used to process each 'slab' of data, ideally returning a vector with names attribute. Defaults to a wrapper function around <code>hdquantile</code>. See details.</p>
</td></tr>
<tr valign="top"><td><code>cpm</code></td>
<td>
<p>Strategy for normalizing slice-wise probabilities, dividing by either: number of profiles with data at the current slice (cpm=1), or by the number of profiles in the collection (cpm=2). Mode 1 values will always sum to the contributing fraction, while mode 2 values will always sum to 1.</p>
</td></tr>
<tr valign="top"><td><code>weights</code></td>
<td>
<p>Column name containing weights. NOT YET IMPLEMENTED</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>further arguments passsed to <code>slab.fun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiple continuous variables OR a single categorical (factor) variable can be aggregated within a call to <code>slab</code>. Basic error checking is performed to make sure that top and bottom horizon boundaries make sense. User-defined aggregate functions (<code>slab.fun</code>) should return a named vector of results. A new, named column will appear in the results of <code>slab</code> for every named element of a vector returned by <code>slab.fun</code>. See examples below for a simple example of a slab function that computes mean, mean-1SD and mean+1SD. The default slab function wraps <code><a href="../../Hmisc/html/hdquantile.html">hdquantile</a></code> from the Hmisc package, which requires at least 2 observations per chunk. Note that if 'group' is a factor it must not contain NAs.
</p>
<p>Execution time scales linearly (slower) with the total number of profiles in <code>object</code>, and exponentially (faster) as the number of profiles / group is increased. <code>slab()</code> and <code>slice()</code> are much faster and require less memory if input data are either numeric or character.
</p>
<p>There are several possible ways to define slabs, using <code>slab.structure</code>:
</p>

<dl>
<dt>a single integer</dt><dd><p>e.g. 10: data are aggregated over a regular sequence of 10-unit thickness slabs</p>
</dd>
<dt>a vector of 2 integers</dt><dd><p>e.g. c(50, 60): data are aggregated over depths spanning 50&ndash;60 units</p>
</dd>
<dt>a vector of 3 or more integers</dt><dd><p>e.g. c(0, 5, 10, 50, 100): data are aggregated over the depths spanning 0&ndash;5, 5&ndash;10, 10&ndash;50, 50&ndash;100 units</p>
</dd>
</dl>
 


<h3>Value</h3>

<p>Output is returned in long format, such that slice-wise aggregates are returned once for each combination of grouping level (optional), variable described in the <code>fm</code> argument, and depth-wise 'slab'.
</p>
<p>Aggregation of numeric variables, using the default slab function:
</p>

<dl>
<dt>variable</dt><dd><p>The names of variables included in the call to <code>slab</code>.</p>
</dd>
<dt>groupname</dt><dd><p>The name of the grouping variable when provided, otherwise a fake grouping variable named 'all.profiles'.</p>
</dd>
<dt>p.q5</dt><dd><p>The slice-wise 5th percentile.</p>
</dd>
<dt>p.q25</dt><dd><p>The slice-wise 25th percentile</p>
</dd>
<dt>p.q50</dt><dd><p>The slice-wise 50th percentile (median)</p>
</dd>
<dt>p.q75</dt><dd><p>The slice-wise 75th percentile</p>
</dd>
<dt>p.q95</dt><dd><p>The slice-wise 95th percentile</p>
</dd>
<dt>top</dt><dd><p>The slab top boundary.</p>
</dd>
<dt>bottom</dt><dd><p>The slab bottom boundary.</p>
</dd>
<dt>contributing_fraction</dt><dd><p>The fraction of profiles contributing to the aggregate value, ranges from 1/n_profiles to 1.</p>
</dd>
</dl>

<p>When a single factor variable is used, slice-wise probabilities for each level of that factor are returned as:
</p>

<dl>
<dt>variable</dt><dd><p>The names of variables included in the call to <code>slab</code>.</p>
</dd>
<dt>groupname</dt><dd><p>The name of the grouping variable when provided, otherwise a fake grouping variable named 'all.profiles'.</p>
</dd>
<dt>A</dt><dd><p>The slice-wise probability of level A</p>
</dd>
<dt>B</dt><dd><p>The slice-wise probability of level B</p>
</dd>
<dt>...</dt><dd></dd>
<dt>n</dt><dd><p>The slice-wise probability of level n</p>
</dd>
<dt>top</dt><dd><p>The slab top boundary.</p>
</dd>
<dt>bottom</dt><dd><p>The slab bottom boundary.</p>
</dd>
<dt>contributing_fraction</dt><dd><p>The fraction of profiles contributing to the aggregate value, ranges from 1/n_profiles to 1.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>data = &quot;SoilProfileCollection&quot;</dt><dd><p>Typical usage, where input is a <code><a href="SoilProfileCollection-class.html">SoilProfileCollection</a></code>.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Arguments to <code>slab</code> have changed with <code>aqp</code> 1.5 (2012-12-29) as part of a code clean-up and optimization. Calculation of weighted-summaries was broken in <code>aqp</code> 1.2-6 (2012-06-26), and removed as of <code>aqp</code> 1.5 (2012-12-29).  <code>slab</code> replaced the previously defined <code>soil.slot.multiple</code> function as of <code>aqp</code> 0.98-8.58 (2011-12-21).</p>


<h3>Author(s)</h3>

<p>D.E. Beaudette</p>


<h3>References</h3>

<p>D.E. Beaudette, P. Roudier, A.T. O'Geen, Algorithms for quantitative pedology: A toolkit for soil scientists, Computers &amp; Geosciences, Volume 52, March 2013, Pages 258-268, 10.1016/j.cageo.2012.10.020.
</p>
<p>Harrell FE, Davis CE (1982): A new distribution-free quantile estimator. Biometrika 69:635-640.
</p>


<h3>See Also</h3>

<p><code><a href="SPC-slice-methods.html">slice</a>, <a href="../../Hmisc/html/hdquantile.html">hdquantile</a></code>
</p>


<h3>Examples</h3>

<pre>
##
## basic examples
##
library(lattice)
library(grid)

# load sample data, upgrade to SoilProfileCollection
data(sp1)
depths(sp1) &lt;- id ~ top + bottom

# aggregate entire collection with two different segment sizes
a &lt;- slab(sp1, fm = ~ prop)
b &lt;- slab(sp1, fm = ~ prop, slab.structure=5)

# check output
str(a)

# stack into long format
ab &lt;- make.groups(a, b)
ab$which &lt;- factor(ab$which, levels=c('a','b'), 
labels=c('1-cm Interval', '5-cm Interval'))

# plot median and IQR
# custom plotting function for uncertainty viz.
xyplot(top ~ p.q50 | which, data=ab, ylab='Depth',
			 xlab='median bounded by 25th and 75th percentiles',
			 lower=ab$p.q25, upper=ab$p.q75, ylim=c(250,-5),
			 panel=panel.depth_function, 
			 prepanel=prepanel.depth_function,
			 cf=ab$contributing_fraction,
			 layout=c(2,1), scales=list(x=list(alternating=1))
			 )


##
## categorical variable example
##
library(reshape)

# normalize horizon names: result is a factor
sp1$name &lt;- generalize.hz(sp1$name, 
new=c('O','A','B','C'), 
pat=c('O', '^A','^B','C'))

# compute slice-wise probability so that it sums to contributing fraction, from 0-150
a &lt;- slab(sp1, fm= ~ name, cpm=1, slab.structure=0:150)

# reshape into long format for plotting
a.long &lt;- melt(a, id.vars=c('top','bottom'), measure.vars=c('O','A','B','C'))

# plot horizon type proportions using panels
xyplot(top ~ value | variable, data=a.long, subset=value &gt; 0,
			 ylim=c(150, -5), type=c('S','g'), horizontal=TRUE, layout=c(4,1), col=1 )

# again, this time using groups
xyplot(top ~ value, data=a.long, groups=variable, subset=value &gt; 0,
			 ylim=c(150, -5), type=c('S','g'), horizontal=TRUE, asp=2)

# adjust probability to size of collection, from 0-150
a.1 &lt;- slab(sp1, fm= ~ name, cpm=2, slab.structure=0:150)

# reshape into long format for plotting
a.1.long &lt;- melt(a.1, id.vars=c('top','bottom'), measure.vars=c('O','A','B','C'))

# combine aggregation from `cpm` modes 1 and 2
g &lt;- make.groups(cmp.mode.1=a.long, cmp.mode.2=a.1.long)

# plot horizon type proportions
xyplot(top ~ value | variable, groups=which, data=g, subset=value &gt; 0,
			 ylim=c(240, -5), type=c('S','g'), horizontal=TRUE, layout=c(4,1), 
			 auto.key=list(lines=TRUE, points=FALSE, columns=2),
			 par.settings=list(superpose.line=list(col=c(1,2))),
       scales=list(alternating=3))


# apply slice-wise evaluation of max probability, and assign ML-horizon at each slice
(gen.hz.ml &lt;- get.ml.hz(a, c('O','A','B','C')))

## Not run: 
##
## multivariate examples
##
data(sp3)

# add new grouping factor
sp3$group &lt;- 'group 1'
sp3$group[as.numeric(sp3$id) &gt; 5] &lt;- 'group 2'
sp3$group &lt;- factor(sp3$group)

# upgrade to SPC
depths(sp3) &lt;- id ~ top + bottom
site(sp3) &lt;- ~ group

# custom 'slab' function, returning mean +/- 1SD
mean.and.sd &lt;- function(values) {
	m &lt;- mean(values, na.rm=TRUE)
	s &lt;- sd(values, na.rm=TRUE)
	upper &lt;- m + s
	lower &lt;- m - s
	res &lt;- c(mean=m, lower=lower, upper=upper)
	return(res)
	}

# aggregate several variables at once, within 'group'
a &lt;- slab(sp3, fm=group ~ L + A + B, slab.fun=mean.and.sd)

# check the results:
# note that 'group' is the column containing group labels
library(lattice)
xyplot(
	top ~ mean | variable, data=a, groups=group,
	lower=a$lower, upper=a$upper, sync.colors=TRUE, alpha=0.5,
	cf=a$contributing_fraction,
	ylim=c(125,-5), layout=c(3,1), scales=list(x=list(relation='free')),
	par.settings=list(superpose.line=list(lwd=2, col=c('RoyalBlue', 'Orange2'))),
	panel=panel.depth_function, 
	prepanel=prepanel.depth_function,
	auto.key=list(columns=2, lines=TRUE, points=FALSE)
)


# compare a single profile to the group-level aggregate values
a.1 &lt;- slab(sp3[1, ], fm=group ~ L + A + B, slab.fun=mean.and.sd)

# manually update the group column
a.1$group &lt;- 'profile 1'

# combine into a single data.frame:
g &lt;- rbind(a, a.1)

# plot with customized line styles
xyplot(
	top ~ mean | variable, data=g, groups=group, subscripts=TRUE, 
	lower=a$lower, upper=a$upper, ylim=c(125,-5),
	layout=c(3,1), scales=list(x=list(relation='free')),
	panel=panel.depth_function, 
	prepanel=prepanel.depth_function,
	sync.colors=TRUE, alpha=0.25,
	par.settings=list(superpose.line=list(col=c('orange', 'royalblue', 'black'), 
  lwd=2, lty=c(1,1,2))),
	auto.key=list(columns=3, lines=TRUE, points=FALSE)
)



## convert mean value for each variable into long format
library(reshape)

# note that depths are no longer in order 
a.wide &lt;- cast(a, group + top + bottom ~ variable, value=c('mean'))

## again, this time for a user-defined slab from 40-60 cm
a &lt;- slab(sp3, fm=group ~ L + A + B, slab.structure=c(40,60), slab.fun=mean.and.sd)

# now we have weighted average properties (within the defined slab)
# for each variable, and each group
(a.wide &lt;- cast(a, group + top + bottom ~ variable, value=c('mean')))

## this time, compute the weighted mean of selected properties, by profile ID
a &lt;- slab(sp3, fm= id ~ L + A + B, slab.structure=c(40,60), slab.fun=mean.and.sd)
(a.wide &lt;- cast(a, id + top + bottom ~ variable, value=c('mean')))


## aggregate the entire collection, using default slab function (hdquantile)
## note the missing left-hand side of the formula
a &lt;- slab(sp3, fm= ~ L + A + B)


## weighted-aggregation -- NOT YET IMPLEMENTED --
# load sample data, upgrade to SoilProfileCollection
data(sp1)
depths(sp1) &lt;- id ~ top + bottom

# generate pretend weights as site-level attribute
set.seed(10101)
sp1$site.wts &lt;- runif(n=length(sp1), min=20, max=100)

## End(Not run)
</pre>

<hr /><div style="text-align: center;">[Package <em>aqp</em> version 1.9.3 <a href="00Index.html">Index</a>]</div>
</body></html>
