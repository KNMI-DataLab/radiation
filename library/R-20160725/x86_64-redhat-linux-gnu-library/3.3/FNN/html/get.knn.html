<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Search Nearest Neighbors</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for get.knn {FNN}"><tr><td>get.knn {FNN}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Search Nearest Neighbors</h2>

<h3>Description</h3>

<p>Fast k-nearest neighbor searching algorithms including a kd-tree, cover-tree
and the algorithm implemented in class package.
</p>


<h3>Usage</h3>

<pre>
  get.knn(data, k=10, algorithm=c("kd_tree", "cover_tree", "CR", "brute"))
  get.knnx(data, query, k=10, algorithm=c("kd_tree", "cover_tree", "CR", "brute"))
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>data</code></td>
<td>
<p>an input data matrix.</p>
</td></tr>
<tr valign="top"><td><code>query</code></td>
<td>
<p>a query data matrix.</p>
</td></tr>
<tr valign="top"><td><code>algorithm</code></td>
<td>
<p>nearest neighbor searching algorithm.</p>
</td></tr>
<tr valign="top"><td><code>k</code></td>
<td>
<p>the maximum number of nearest neighbors to search. The default value
is set to 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>cover tree</em> is O(n) space data structure which allows us to answer queries
in the same O(log(n)) time as <em>kd tree</em> given a fixed intrinsic dimensionality.
Templated code from <a href="http://hunch.net/~jl/projects/cover_tree/cover_tree.html">http://hunch.net/~jl/projects/cover_tree/cover_tree.html</a> is used.
</p>
<p>The <em>kd tree</em> algorithm is implemented in the Approximate Near Neighbor (ANN) C++ library (see  <a href="http://www.cs.umd.edu/~mount/ANN/">http://www.cs.umd.edu/~mount/ANN/</a>).
The exact nearest neighbors are searched in this package.
</p>
<p>The <em>CR</em> algorithm is the <em>VR</em> using distance <em>1-x'y</em> assuming <code>x</code> and <code>y</code> are unit vectors.
The <em>brute</em> algorithm searches linearly. It is a naive method.
</p>


<h3>Value</h3>

<p>a list contains:
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>nn.index</code></td>
<td>
<p>an n x k matrix for the nearest neighbor indice.</p>
</td></tr>
<tr valign="top"><td><code>nn.dist</code></td>
<td>
<p>an n x k matrix for the nearest neighbor Euclidean distances.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:shli@stat.wvu.edu.">shli@stat.wvu.edu.</a></p>


<h3>References</h3>

<p>Bentley J.L. (1975), &ldquo;Multidimensional binary search trees used for associative
search,&rdquo; <em>Communication ACM</em>, <b>18</b>, 309-517.
</p>
<p>Arya S. and Mount D.M. (1993),
&ldquo;Approximate nearest neighbor searching,&rdquo;
<em>Proc. 4th Ann. ACM-SIAM Symposium on Discrete Algorithms (SODA'93)</em>, 271-280.
</p>
<p>Arya S., Mount D.M., Netanyahu N.S., Silverman R. and Wu A.Y. (1998),
&ldquo;An optimal algorithm for approximate nearest neighbor searching,&rdquo;
<em>Journal of the ACM</em>, <b>45</b>, 891-923.
</p>
<p>Beygelzimer A., Kakade S. and Langford J. (2006),
&ldquo;Cover trees for nearest neighbor,&rdquo;
<em>ACM Proc. 23rd international conference on Machine learning</em>, <b>148</b>, 97-104.
</p>


<h3>See Also</h3>

<p><code>nn2</code> in <span class="pkg">RANN</span>, <code>ann</code> in <span class="pkg">yaImpute</span> and <code><a href="../../class/html/knn.html">knn</a></code> in <span class="pkg">class</span>.
</p>


<h3>Examples</h3>

<pre>
  data&lt;- query&lt;- cbind(1:10, 1:10)

  get.knn(data, k=5)
  get.knnx(data, query, k=5)
  get.knnx(data, query, k=5, algo="kd_tree")

</pre>

<hr /><div style="text-align: center;">[Package <em>FNN</em> version 1.1 <a href="00Index.html">Index</a>]</div>
</body></html>
