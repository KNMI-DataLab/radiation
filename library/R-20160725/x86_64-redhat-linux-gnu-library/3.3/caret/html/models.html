<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: A List of Available Models in train</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for train_model_list {caret}"><tr><td>train_model_list {caret}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>A List of Available Models in train</h2>

<h3>Description</h3>

<p>These models are included in the package via wrappers for <code><a href="train.html">train</a></code>. Custom models can also be created. See the URL below.
</p>
<p><strong>AdaBoost Classification Trees</strong> (<code>method = 'adaboost'</code>)
</p>
<p>For classification using package <span class="pkg">fastAdaboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>nIter</code>, numeric)
</p>
</li>
<li><p> Method (<code>method</code>, character)
</p>
</li></ul>

<p><strong>AdaBoost.M1</strong> (<code>method = 'AdaBoost.M1'</code>)
</p>
<p>For classification using packages <span class="pkg">adabag</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>mfinal</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> Coefficient Type (<code>coeflearn</code>, character)
</p>
</li></ul>

<p><strong>Adaptive Mixture Discriminant Analysis</strong> (<code>method = 'amdai'</code>)
</p>
<p>For classification using package <span class="pkg">adaptDA</span> with tuning parameters:
</p>

<ul>
<li><p> Model Type (<code>model</code>, character)
</p>
</li></ul>

<p><strong>Adaptive-Network-Based Fuzzy Inference System</strong> (<code>method = 'ANFIS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Adjacent Categories Probability Model for Ordinal Data</strong> (<code>method = 'vglmAdjCat'</code>)
</p>
<p>For classification using package <span class="pkg">VGAM</span> with tuning parameters:
</p>

<ul>
<li><p> Parallel Curves (<code>parallel</code>, logical)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>Bagged AdaBoost</strong> (<code>method = 'AdaBag'</code>)
</p>
<p>For classification using packages <span class="pkg">adabag</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>mfinal</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged CART</strong> (<code>method = 'treebag'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">ipred</span>, <span class="pkg">plyr</span> and <span class="pkg">e1071</span> with no tuning parameters
</p>
<p><strong>Bagged FDA using gCV Pruning</strong> (<code>method = 'bagFDAGCV'</code>)
</p>
<p>For classification using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged Flexible Discriminant Analysis</strong> (<code>method = 'bagFDA'</code>)
</p>
<p>For classification using packages <span class="pkg">earth</span> and <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged Logic Regression</strong> (<code>method = 'logicBag'</code>)
</p>
<p>For classification and regression using package <span class="pkg">logicFS</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Leaves (<code>nleaves</code>, numeric)
</p>
</li>
<li><p> Number of Trees (<code>ntrees</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged MARS</strong> (<code>method = 'bagEarth'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged MARS using gCV Pruning</strong> (<code>method = 'bagEarthGCV'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Bagged Model</strong> (<code>method = 'bag'</code>)
</p>
<p>For classification and regression using package <span class="pkg">caret</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>vars</code>, numeric)
</p>
</li></ul>

<p><strong>Bayesian Additive Regression Trees</strong> (<code>method = 'bartMachine'</code>)
</p>
<p>For classification and regression using package <span class="pkg">bartMachine</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>num_trees</code>, numeric)
</p>
</li>
<li><p> Prior Boundary (<code>k</code>, numeric)
</p>
</li>
<li><p> Base Terminal Node Hyperparameter (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Power Terminal Node Hyperparameter (<code>beta</code>, numeric)
</p>
</li>
<li><p> Degrees of Freedom (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Bayesian Generalized Linear Model</strong> (<code>method = 'bayesglm'</code>)
</p>
<p>For classification and regression using package <span class="pkg">arm</span> with no tuning parameters
</p>
<p><strong>Bayesian Regularized Neural Networks</strong> (<code>method = 'brnn'</code>)
</p>
<p>For regression using package <span class="pkg">brnn</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Neurons (<code>neurons</code>, numeric)
</p>
</li></ul>

<p><strong>Bayesian Ridge Regression</strong> (<code>method = 'bridge'</code>)
</p>
<p>For regression using package <span class="pkg">monomvn</span> with no tuning parameters
</p>
<p><strong>Bayesian Ridge Regression (Model Averaged)</strong> (<code>method = 'blassoAveraged'</code>)
</p>
<p>For regression using package <span class="pkg">monomvn</span> with no tuning parameters
</p>
<p><strong>Binary Discriminant Analysis</strong> (<code>method = 'binda'</code>)
</p>
<p>For classification using package <span class="pkg">binda</span> with tuning parameters:
</p>

<ul>
<li><p> Shrinkage Intensity (<code>lambda.freqs</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Classification Trees</strong> (<code>method = 'ada'</code>)
</p>
<p>For classification using packages <span class="pkg">ada</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>iter</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Generalized Additive Model</strong> (<code>method = 'gamboost'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">mboost</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> AIC Prune? (<code>prune</code>, character)
</p>
</li></ul>

<p><strong>Boosted Generalized Linear Model</strong> (<code>method = 'glmboost'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">plyr</span> and <span class="pkg">mboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> AIC Prune? (<code>prune</code>, character)
</p>
</li></ul>

<p><strong>Boosted Linear Model</strong> (<code>method = 'BstLm'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">bst</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Logistic Regression</strong> (<code>method = 'LogitBoost'</code>)
</p>
<p>For classification using package <span class="pkg">caTools</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nIter</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Smoothing Spline</strong> (<code>method = 'bstSm'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">bst</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Tree</strong> (<code>method = 'blackboost'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">party</span>, <span class="pkg">mboost</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Trees (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>Boosted Tree</strong> (<code>method = 'bstTree'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">bst</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>mstop</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>nu</code>, numeric)
</p>
</li></ul>

<p><strong>C4.5-like Trees</strong> (<code>method = 'J48'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Confidence Threshold (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>C5.0</strong> (<code>method = 'C5.0'</code>)
</p>
<p>For classification using packages <span class="pkg">C50</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>trials</code>, numeric)
</p>
</li>
<li><p> Model Type (<code>model</code>, character)
</p>
</li>
<li><p> Winnow (<code>winnow</code>, logical)
</p>
</li></ul>

<p><strong>CART</strong> (<code>method = 'rpart'</code>)
</p>
<p>For classification and regression using package <span class="pkg">rpart</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li></ul>

<p><strong>CART</strong> (<code>method = 'rpart1SE'</code>)
</p>
<p>For classification and regression using package <span class="pkg">rpart</span> with no tuning parameters
</p>
<p><strong>CART</strong> (<code>method = 'rpart2'</code>)
</p>
<p>For classification and regression using package <span class="pkg">rpart</span> with tuning parameters:
</p>

<ul>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>CART or Ordinal Responses</strong> (<code>method = 'rpartScore'</code>)
</p>
<p>For classification using packages <span class="pkg">rpartScore</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li>
<li><p> Split Function (<code>split</code>, character)
</p>
</li>
<li><p> Pruning Measure (<code>prune</code>, character)
</p>
</li></ul>

<p><strong>CHi-squared Automated Interaction Detection</strong> (<code>method = 'chaid'</code>)
</p>
<p>For classification using package <span class="pkg">CHAID</span> with tuning parameters:
</p>

<ul>
<li><p> Merging Threshold (<code>alpha2</code>, numeric)
</p>
</li>
<li><p> Splitting former Merged Threshold (<code>alpha3</code>, numeric)
</p>
</li>
<li> 
<p>Splitting former Merged Threshold (<code>alpha4</code>, numeric)
</p>
</li></ul>

<p><strong>Conditional Inference Random Forest</strong> (<code>method = 'cforest'</code>)
</p>
<p>For classification and regression using package <span class="pkg">party</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Conditional Inference Tree</strong> (<code>method = 'ctree'</code>)
</p>
<p>For classification and regression using package <span class="pkg">party</span> with tuning parameters:
</p>

<ul>
<li><p> 1 - P-Value Threshold (<code>mincriterion</code>, numeric)
</p>
</li></ul>

<p><strong>Conditional Inference Tree</strong> (<code>method = 'ctree2'</code>)
</p>
<p>For classification and regression using package <span class="pkg">party</span> with tuning parameters:
</p>

<ul>
<li><p> Max Tree Depth (<code>maxdepth</code>, numeric)
</p>
</li>
<li><p> 1 - P-Value Threshold (<code>mincriterion</code>, numeric)
</p>
</li></ul>

<p><strong>Continuation Ratio Model for Ordinal Data</strong> (<code>method = 'vglmContRatio'</code>)
</p>
<p>For classification using package <span class="pkg">VGAM</span> with tuning parameters:
</p>

<ul>
<li><p> Parallel Curves (<code>parallel</code>, logical)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>Cost-Sensitive C5.0</strong> (<code>method = 'C5.0Cost'</code>)
</p>
<p>For classification using packages <span class="pkg">C50</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>trials</code>, numeric)
</p>
</li>
<li><p> Model Type (<code>model</code>, character)
</p>
</li>
<li><p> Winnow (<code>winnow</code>, logical)
</p>
</li>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li></ul>

<p><strong>Cost-Sensitive CART</strong> (<code>method = 'rpartCost'</code>)
</p>
<p>For classification using package <span class="pkg">rpart</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li>
<li><p> Cost (<code>Cost</code>, numeric)
</p>
</li></ul>

<p><strong>Cubist</strong> (<code>method = 'cubist'</code>)
</p>
<p>For regression using package <span class="pkg">Cubist</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Committees (<code>committees</code>, numeric)
</p>
</li>
<li><p> Number of Instances (<code>neighbors</code>, numeric)
</p>
</li></ul>

<p><strong>Cumulative Probability Model for Ordinal Data</strong> (<code>method = 'vglmCumulative'</code>)
</p>
<p>For classification using package <span class="pkg">VGAM</span> with tuning parameters:
</p>

<ul>
<li><p> Parallel Curves (<code>parallel</code>, logical)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>DeepBoost</strong> (<code>method = 'deepboost'</code>)
</p>
<p>For classification using package <span class="pkg">deepboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>num_iter</code>, numeric)
</p>
</li>
<li><p> Tree Depth (<code>tree_depth</code>, numeric)
</p>
</li>
<li><p> L1 Regularization (<code>beta</code>, numeric)
</p>
</li>
<li><p> Tree Depth Regularization (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Loss (<code>loss_type</code>, character)
</p>
</li></ul>

<p><strong>Diagonal Discriminant Analysis</strong> (<code>method = 'dda'</code>)
</p>
<p>For classification using package <span class="pkg">sparsediscrim</span> with tuning parameters:
</p>

<ul>
<li><p> Model (<code>model</code>, character)
</p>
</li>
<li><p> Shrinkage Type (<code>shrinkage</code>, character)
</p>
</li></ul>

<p><strong>Distance Weighted Discrimination with Polynomial Kernel</strong> (<code>method = 'dwdPoly'</code>)
</p>
<p>For classification using package <span class="pkg">kerndwd</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> q (<code>qval</code>, numeric)
</p>
</li>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li></ul>

<p><strong>Distance Weighted Discrimination with Radial Basis Function Kernel</strong> (<code>method = 'dwdRadial'</code>)
</p>
<p>For classification using packages <span class="pkg">kernlab</span> and <span class="pkg">kerndwd</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> q (<code>qval</code>, numeric)
</p>
</li>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Dynamic Evolving Neural-Fuzzy Inference System </strong> (<code>method = 'DENFIS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Threshold (<code>Dthr</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Elasticnet</strong> (<code>method = 'enet'</code>)
</p>
<p>For regression using package <span class="pkg">elasticnet</span> with tuning parameters:
</p>

<ul>
<li><p> Fraction of Full Solution (<code>fraction</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Ensemble Partial Least Squares Regression</strong> (<code>method = 'enpls'</code>)
</p>
<p>For regression using package <span class="pkg">enpls</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Number of Components (<code>maxcomp</code>, numeric)
</p>
</li></ul>

<p><strong>Ensemble Partial Least Squares Regression with Feature Selection</strong> (<code>method = 'enpls.fs'</code>)
</p>
<p>For regression using package <span class="pkg">enpls</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Number of Components (<code>maxcomp</code>, numeric)
</p>
</li>
<li><p> Importance Cutoff (<code>threshold</code>, numeric)
</p>
</li></ul>

<p><strong>Ensembles of Generalized Lienar Models</strong> (<code>method = 'randomGLM'</code>)
</p>
<p>For classification and regression using package <span class="pkg">randomGLM</span> with tuning parameters:
</p>

<ul>
<li><p> Interaction Order (<code>maxInteractionOrder</code>, numeric)
</p>
</li></ul>

<p><strong>eXtreme Gradient Boosting</strong> (<code>method = 'xgbLinear'</code>)
</p>
<p>For classification and regression using package <span class="pkg">xgboost</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nrounds</code>, numeric)
</p>
</li>
<li><p> L2 Regularization (<code>lambda</code>, numeric)
</p>
</li>
<li><p> L1 Regularization (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>eta</code>, numeric)
</p>
</li></ul>

<p><strong>eXtreme Gradient Boosting</strong> (<code>method = 'xgbTree'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">xgboost</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>nrounds</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>max_depth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>eta</code>, numeric)
</p>
</li>
<li><p> Minimum Loss Reduction (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Subsample Ratio of Columns (<code>colsample_bytree</code>, numeric)
</p>
</li>
<li><p> Minimum Sum of Instance Weight (<code>min_child_weight</code>, numeric)
</p>
</li></ul>

<p><strong>Extreme Learning Machine</strong> (<code>method = 'elm'</code>)
</p>
<p>For classification and regression using package <span class="pkg">elmNN</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>nhid</code>, numeric)
</p>
</li>
<li><p> Activation Function (<code>actfun</code>, character)
</p>
</li></ul>

<p><strong>Factor-Based Linear Discriminant Analysis</strong> (<code>method = 'RFlda'</code>)
</p>
<p>For classification using package <span class="pkg">HiDimDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Factors (<code>q</code>, numeric)
</p>
</li></ul>

<p><strong>Flexible Discriminant Analysis</strong> (<code>method = 'fda'</code>)
</p>
<p>For classification using packages <span class="pkg">earth</span> and <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Inference Rules by Descent Method</strong> (<code>method = 'FIR.DM'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using Chi's Method</strong> (<code>method = 'FRBCS.CHI'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Membership Function (<code>type.mf</code>, character)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using Genetic Cooperative-Competitive Learning</strong> (<code>method = 'GFS.GCCL'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using Genetic Cooperative-Competitive Learning and Pittsburgh</strong> (<code>method = 'FH.GBML'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Number of Rules (<code>max.num.rule</code>, numeric)
</p>
</li>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules Using the Structural Learning Algorithm on Vague Environment</strong> (<code>method = 'SLAVE'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules via MOGUL</strong> (<code>method = 'GFS.FR.MOGUL'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li>
<li><p> Max. Tuning Iterations (<code>max.tune</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules via Thrift</strong> (<code>method = 'GFS.THRIFT'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Number of  Fuzzy Labels (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>Fuzzy Rules with Weight Factor</strong> (<code>method = 'FRBCS.W'</code>)
</p>
<p>For classification using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Membership Function (<code>type.mf</code>, character)
</p>
</li></ul>

<p><strong>Gaussian Process</strong> (<code>method = 'gaussprLinear'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with no tuning parameters
</p>
<p><strong>Gaussian Process with Polynomial Kernel</strong> (<code>method = 'gaussprPoly'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li></ul>

<p><strong>Gaussian Process with Radial Basis Function Kernel</strong> (<code>method = 'gaussprRadial'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Generalized Additive Model using LOESS</strong> (<code>method = 'gamLoess'</code>)
</p>
<p>For classification and regression using package <span class="pkg">gam</span> with tuning parameters:
</p>

<ul>
<li><p> Span (<code>span</code>, numeric)
</p>
</li>
<li><p> Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Generalized Additive Model using Splines</strong> (<code>method = 'bam'</code>)
</p>
<p>For classification and regression using package <span class="pkg">mgcv</span> with tuning parameters:
</p>

<ul>
<li><p> Feature Selection (<code>select</code>, logical)
</p>
</li>
<li><p> Method (<code>method</code>, character)
</p>
</li></ul>

<p><strong>Generalized Additive Model using Splines</strong> (<code>method = 'gam'</code>)
</p>
<p>For classification and regression using package <span class="pkg">mgcv</span> with tuning parameters:
</p>

<ul>
<li><p> Feature Selection (<code>select</code>, logical)
</p>
</li>
<li><p> Method (<code>method</code>, character)
</p>
</li></ul>

<p><strong>Generalized Additive Model using Splines</strong> (<code>method = 'gamSpline'</code>)
</p>
<p>For classification and regression using package <span class="pkg">gam</span> with tuning parameters:
</p>

<ul>
<li><p> Degrees of Freedom (<code>df</code>, numeric)
</p>
</li></ul>

<p><strong>Generalized Linear Model</strong> (<code>method = 'glm'</code>)
</p>
<p>For classification and regression with no tuning parameters
</p>
<p><strong>Generalized Linear Model with Stepwise Feature Selection</strong> (<code>method = 'glmStepAIC'</code>)
</p>
<p>For classification and regression using package <span class="pkg">MASS</span> with no tuning parameters
</p>
<p><strong>Generalized Partial Least Squares</strong> (<code>method = 'gpls'</code>)
</p>
<p>For classification using package <span class="pkg">gpls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>K.prov</code>, numeric)
</p>
</li></ul>

<p><strong>Genetic Lateral Tuning and Rule Selection of Linguistic Fuzzy Systems</strong> (<code>method = 'GFS.LT.RS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Population Size (<code>popu.size</code>, numeric)
</p>
</li>
<li><p> Number of  Fuzzy Labels (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Generations (<code>max.gen</code>, numeric)
</p>
</li></ul>

<p><strong>glmnet</strong> (<code>method = 'glmnet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">glmnet</span> with tuning parameters:
</p>

<ul>
<li><p> Mixing Percentage (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Greedy Prototype Selection</strong> (<code>method = 'protoclass'</code>)
</p>
<p>For classification using packages <span class="pkg">proxy</span> and <span class="pkg">protoclass</span> with tuning parameters:
</p>

<ul>
<li><p> Ball Size (<code>eps</code>, numeric)
</p>
</li>
<li><p> Distance Order (<code>Minkowski</code>, numeric)
</p>
</li></ul>

<p><strong>Heteroscedastic Discriminant Analysis</strong> (<code>method = 'hda'</code>)
</p>
<p>For classification using package <span class="pkg">hda</span> with tuning parameters:
</p>

<ul>
<li><p> Gamma (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Dimension of the Discriminative Subspace (<code>newdim</code>, numeric)
</p>
</li></ul>

<p><strong>High Dimensional Discriminant Analysis</strong> (<code>method = 'hdda'</code>)
</p>
<p>For classification using package <span class="pkg">HDclassif</span> with tuning parameters:
</p>

<ul>
<li><p> Threshold (<code>threshold</code>, character)
</p>
</li>
<li><p> Model Type (<code>model</code>, numeric)
</p>
</li></ul>

<p><strong>High-Dimensional Regularized Discriminant Analysis</strong> (<code>method = 'hdrda'</code>)
</p>
<p>For classification using package <span class="pkg">sparsediscrim</span> with tuning parameters:
</p>

<ul>
<li><p> Gamma (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Shrinkage Type (<code>shrinkage_type</code>, character)
</p>
</li></ul>

<p><strong>Hybrid Neural Fuzzy Inference System</strong> (<code>method = 'HYFIS'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Independent Component Regression</strong> (<code>method = 'icr'</code>)
</p>
<p>For regression using package <span class="pkg">fastICA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>n.comp</code>, numeric)
</p>
</li></ul>

<p><strong>k-Nearest Neighbors</strong> (<code>method = 'kknn'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kknn</span> with tuning parameters:
</p>

<ul>
<li><p> Max. Number of Neighbors (<code>kmax</code>, numeric)
</p>
</li>
<li><p> Distance (<code>distance</code>, numeric)
</p>
</li>
<li><p> Kernel (<code>kernel</code>, character)
</p>
</li></ul>

<p><strong>k-Nearest Neighbors</strong> (<code>method = 'knn'</code>)
</p>
<p>For classification and regression with tuning parameters:
</p>

<ul>
<li><p> Number of Neighbors (<code>k</code>, numeric)
</p>
</li></ul>

<p><strong>Knn regression via sklearn.neighbors.KNeighborsRegressor</strong> (<code>method = 'pythonKnnReg'</code>)
</p>
<p>For regression using package <span class="pkg">rPython</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Neighbors (<code>n_neighbors</code>, numeric)
</p>
</li>
<li><p> Weight Function (<code>weights</code>, character)
</p>
</li>
<li><p> Algorithm (<code>algorithm</code>, character)
</p>
</li>
<li><p> Leaf Size (<code>leaf_size</code>, numeric)
</p>
</li>
<li><p> Distance Metric (<code>metric</code>, character)
</p>
</li>
<li><p> p (<code>p</code>, numeric)
</p>
</li></ul>

<p><strong>L2 Regularized Linear Support Vector Machines with Class Weights</strong> (<code>method = 'svmLinearWeights2'</code>)
</p>
<p>For classification using package <span class="pkg">LiblineaR</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Loss Function (<code>Loss</code>, character)
</p>
</li>
<li><p> Class Weight (<code>weight</code>, numeric)
</p>
</li></ul>

<p><strong>L2 Regularized Support Vector Machine (dual) with Linear Kernel</strong> (<code>method = 'svmLinear3'</code>)
</p>
<p>For classification and regression using package <span class="pkg">LiblineaR</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Loss Function (<code>Loss</code>, character)
</p>
</li></ul>

<p><strong>Learning Vector Quantization</strong> (<code>method = 'lvq'</code>)
</p>
<p>For classification using package <span class="pkg">class</span> with tuning parameters:
</p>

<ul>
<li><p> Codebook Size (<code>size</code>, numeric)
</p>
</li>
<li><p> Number of Prototypes (<code>k</code>, numeric)
</p>
</li></ul>

<p><strong>Least Angle Regression</strong> (<code>method = 'lars'</code>)
</p>
<p>For regression using package <span class="pkg">lars</span> with tuning parameters:
</p>

<ul>
<li><p> Fraction (<code>fraction</code>, numeric)
</p>
</li></ul>

<p><strong>Least Angle Regression</strong> (<code>method = 'lars2'</code>)
</p>
<p>For regression using package <span class="pkg">lars</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Steps (<code>step</code>, numeric)
</p>
</li></ul>

<p><strong>Least Squares Support Vector Machine</strong> (<code>method = 'lssvmLinear'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>tau</code>, numeric)
</p>
</li></ul>

<p><strong>Least Squares Support Vector Machine with Polynomial Kernel</strong> (<code>method = 'lssvmPoly'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>tau</code>, numeric)
</p>
</li></ul>

<p><strong>Least Squares Support Vector Machine with Radial Basis Function Kernel</strong> (<code>method = 'lssvmRadial'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Regularization Parameter (<code>tau</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Discriminant Analysis</strong> (<code>method = 'lda'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with no tuning parameters
</p>
<p><strong>Linear Discriminant Analysis</strong> (<code>method = 'lda2'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Discriminant Functions (<code>dimen</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Discriminant Analysis with Stepwise Feature Selection</strong> (<code>method = 'stepLDA'</code>)
</p>
<p>For classification using packages <span class="pkg">klaR</span> and <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Variables (<code>maxvar</code>, numeric)
</p>
</li>
<li><p> Search Direction (<code>direction</code>, character)
</p>
</li></ul>

<p><strong>Linear Distance Weighted Discrimination</strong> (<code>method = 'dwdLinear'</code>)
</p>
<p>For classification using package <span class="pkg">kerndwd</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> q (<code>qval</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression</strong> (<code>method = 'lm'</code>)
</p>
<p>For regression with tuning parameters:
</p>

<ul>
<li><p> intercept (<code>intercept</code>, logical)
</p>
</li></ul>

<p><strong>Linear Regression with Backwards Selection</strong> (<code>method = 'leapBackward'</code>)
</p>
<p>For regression using package <span class="pkg">leaps</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Predictors (<code>nvmax</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression with Forward Selection</strong> (<code>method = 'leapForward'</code>)
</p>
<p>For regression using package <span class="pkg">leaps</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Predictors (<code>nvmax</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression with Stepwise Selection</strong> (<code>method = 'leapSeq'</code>)
</p>
<p>For regression using package <span class="pkg">leaps</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Predictors (<code>nvmax</code>, numeric)
</p>
</li></ul>

<p><strong>Linear Regression with Stepwise Selection</strong> (<code>method = 'lmStepAIC'</code>)
</p>
<p>For regression using package <span class="pkg">MASS</span> with no tuning parameters
</p>
<p><strong>Linear Support Vector Machines with Class Weights</strong> (<code>method = 'svmLinearWeights'</code>)
</p>
<p>For classification using package <span class="pkg">e1071</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li>
<li><p> Class Weight (<code>weight</code>, numeric)
</p>
</li></ul>

<p><strong>Localized Linear Discriminant Analysis</strong> (<code>method = 'loclda'</code>)
</p>
<p>For classification using package <span class="pkg">klaR</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Nearest Neighbors (<code>k</code>, numeric)
</p>
</li></ul>

<p><strong>Logic Regression</strong> (<code>method = 'logreg'</code>)
</p>
<p>For classification and regression using package <span class="pkg">LogicReg</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Leaves (<code>treesize</code>, numeric)
</p>
</li>
<li><p> Number of Trees (<code>ntrees</code>, numeric)
</p>
</li></ul>

<p><strong>Logistic Model Trees</strong> (<code>method = 'LMT'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Iteratons (<code>iter</code>, numeric)
</p>
</li></ul>

<p><strong>Maximum Uncertainty Linear Discriminant Analysis</strong> (<code>method = 'Mlda'</code>)
</p>
<p>For classification using package <span class="pkg">HiDimDA</span> with no tuning parameters
</p>
<p><strong>Mixture Discriminant Analysis</strong> (<code>method = 'mda'</code>)
</p>
<p>For classification using package <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Subclasses Per Class (<code>subclasses</code>, numeric)
</p>
</li></ul>

<p><strong>Model Averaged Naive Bayes Classifier</strong> (<code>method = 'manb'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li>
<li><p> Prior Probability (<code>prior</code>, numeric)
</p>
</li></ul>

<p><strong>Model Averaged Neural Network</strong> (<code>method = 'avNNet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li>
<li><p> Bagging (<code>bag</code>, logical)
</p>
</li></ul>

<p><strong>Model Rules</strong> (<code>method = 'M5Rules'</code>)
</p>
<p>For regression using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Pruned (<code>pruned</code>, character)
</p>
</li>
<li><p> Smoothed (<code>smoothed</code>, character)
</p>
</li></ul>

<p><strong>Model Tree</strong> (<code>method = 'M5'</code>)
</p>
<p>For regression using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Pruned (<code>pruned</code>, character)
</p>
</li>
<li><p> Smoothed (<code>smoothed</code>, character)
</p>
</li>
<li><p> Rules (<code>rules</code>, character)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron</strong> (<code>method = 'mlp'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron</strong> (<code>method = 'mlpWeightDecay'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron, multiple layers</strong> (<code>method = 'mlpWeightDecayML'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units layer1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer3 (<code>layer3</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Multi-Layer Perceptron, with multiple layers</strong> (<code>method = 'mlpML'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units layer1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units layer3 (<code>layer3</code>, numeric)
</p>
</li></ul>

<p><strong>Multilayer Perceptron Network by Stochastic Gradient Descent</strong> (<code>method = 'mlpSGD'</code>)
</p>
<p>For regression using package <span class="pkg">FCNN4R</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> L2 Regularization (<code>l2reg</code>, numeric)
</p>
</li>
<li><p> RMSE Gradient Scaling (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Learning Rate (<code>learn_rate</code>, numeric)
</p>
</li>
<li><p> Momentum (<code>momentum</code>, numeric)
</p>
</li>
<li><p> Decay (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Batch Size (<code>minibatchsz</code>, numeric)
</p>
</li>
<li><p> Number of Models (<code>repeats</code>, numeric)
</p>
</li></ul>

<p><strong>Multivariate Adaptive Regression Spline</strong> (<code>method = 'earth'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Terms (<code>nprune</code>, numeric)
</p>
</li>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Multivariate Adaptive Regression Splines</strong> (<code>method = 'gcvEarth'</code>)
</p>
<p>For classification and regression using package <span class="pkg">earth</span> with tuning parameters:
</p>

<ul>
<li><p> Product Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Naive Bayes</strong> (<code>method = 'nb'</code>)
</p>
<p>For classification using package <span class="pkg">klaR</span> with tuning parameters:
</p>

<ul>
<li><p> Laplace Correction (<code>fL</code>, numeric)
</p>
</li>
<li><p> Distribution Type (<code>usekernel</code>, logical)
</p>
</li>
<li><p> Bandwidth Adjustment (<code>adjust</code>, numeric)
</p>
</li></ul>

<p><strong>Naive Bayes Classifier</strong> (<code>method = 'nbDiscrete'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Naive Bayes Classifier with Attribute Weighting</strong> (<code>method = 'awnb'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Nearest Shrunken Centroids</strong> (<code>method = 'pam'</code>)
</p>
<p>For classification using package <span class="pkg">pamr</span> with tuning parameters:
</p>

<ul>
<li><p> Shrinkage Threshold (<code>threshold</code>, numeric)
</p>
</li></ul>

<p><strong>Neural Network</strong> (<code>method = 'neuralnet'</code>)
</p>
<p>For regression using package <span class="pkg">neuralnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units in Layer 1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Number of Hidden Units in Layer 3 (<code>layer3</code>, numeric)
</p>
</li></ul>

<p><strong>Neural Network</strong> (<code>method = 'nnet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Neural Networks with Feature Extraction</strong> (<code>method = 'pcaNNet'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Non-Convex Penalized Quantile Regression</strong> (<code>method = 'rqnc'</code>)
</p>
<p>For regression using package <span class="pkg">rqPen</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Penalty Type (<code>penalty</code>, character)
</p>
</li></ul>

<p><strong>Non-Negative Least Squares</strong> (<code>method = 'nnls'</code>)
</p>
<p>For regression using package <span class="pkg">nnls</span> with no tuning parameters
</p>
<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFlog'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFpls'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFridge'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Oblique Random Forest</strong> (<code>method = 'ORFsvm'</code>)
</p>
<p>For classification using package <span class="pkg">obliqueRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Oblique Trees</strong> (<code>method = 'oblique.tree'</code>)
</p>
<p>For classification using package <span class="pkg">oblique.tree</span> with tuning parameters:
</p>

<ul>
<li><p> Oblique Splits (<code>oblique.splits</code>, character)
</p>
</li>
<li><p> Variable Selection Method (<code>variable.selection</code>, character)
</p>
</li></ul>

<p><strong>Optimal Weighted Nearest Neighbor Classifier</strong> (<code>method = 'ownn'</code>)
</p>
<p>For classification using package <span class="pkg">snn</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Neighbors (<code>K</code>, numeric)
</p>
</li></ul>

<p><strong>Ordered Logistic or Probit Regression</strong> (<code>method = 'polr'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> parameter (<code>method</code>, character)
</p>
</li></ul>

<p><strong>Parallel Random Forest</strong> (<code>method = 'parRF'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">e1071</span>, <span class="pkg">randomForest</span> and <span class="pkg">foreach</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>partDSA</strong> (<code>method = 'partDSA'</code>)
</p>
<p>For classification and regression using package <span class="pkg">partDSA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Terminal Partitions (<code>cut.off.growth</code>, numeric)
</p>
</li>
<li><p> Minimum Percent Difference (<code>MPD</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'kernelpls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'pls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'simpls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares</strong> (<code>method = 'widekernelpls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Partial Least Squares Generalized Linear Models </strong> (<code>method = 'plsRglm'</code>)
</p>
<p>For classification and regression using package <span class="pkg">plsRglm</span> with tuning parameters:
</p>

<ul>
<li><p> Number of PLS Components (<code>nt</code>, numeric)
</p>
</li>
<li><p> p-Value threshold (<code>alpha.pvals.expli</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Discriminant Analysis</strong> (<code>method = 'pda'</code>)
</p>
<p>For classification using package <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Shrinkage Penalty Coefficient (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Discriminant Analysis</strong> (<code>method = 'pda2'</code>)
</p>
<p>For classification using package <span class="pkg">mda</span> with tuning parameters:
</p>

<ul>
<li><p> Degrees of Freedom (<code>df</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Linear Discriminant Analysis</strong> (<code>method = 'PenalizedLDA'</code>)
</p>
<p>For classification using packages <span class="pkg">penalizedLDA</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Number of Discriminant Functions (<code>K</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Linear Regression</strong> (<code>method = 'penalized'</code>)
</p>
<p>For regression using package <span class="pkg">penalized</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda1</code>, numeric)
</p>
</li>
<li><p> L2 Penalty (<code>lambda2</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Logistic Regression</strong> (<code>method = 'plr'</code>)
</p>
<p>For classification using package <span class="pkg">stepPlr</span> with tuning parameters:
</p>

<ul>
<li><p> L2 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Complexity Parameter (<code>cp</code>, character)
</p>
</li></ul>

<p><strong>Penalized Multinomial Regression</strong> (<code>method = 'multinom'</code>)
</p>
<p>For classification using package <span class="pkg">nnet</span> with tuning parameters:
</p>

<ul>
<li><p> Weight Decay (<code>decay</code>, numeric)
</p>
</li></ul>

<p><strong>Penalized Ordinal Regression</strong> (<code>method = 'ordinalNet'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">ordinalNet</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Mixing Percentage (<code>alpha</code>, numeric)
</p>
</li>
<li><p> Selection Criterion (<code>criteria</code>, character)
</p>
</li>
<li><p> Link Function (<code>link</code>, character)
</p>
</li></ul>

<p><strong>Polynomial Kernel Regularized Least Squares</strong> (<code>method = 'krlsPoly'</code>)
</p>
<p>For regression using package <span class="pkg">KRLS</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Principal Component Analysis</strong> (<code>method = 'pcr'</code>)
</p>
<p>For regression using package <span class="pkg">pls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>ncomp</code>, numeric)
</p>
</li></ul>

<p><strong>Projection Pursuit Regression</strong> (<code>method = 'ppr'</code>)
</p>
<p>For regression with tuning parameters:
</p>

<ul>
<li><p> Number of  Terms (<code>nterms</code>, numeric)
</p>
</li></ul>

<p><strong>Quadratic Discriminant Analysis</strong> (<code>method = 'qda'</code>)
</p>
<p>For classification using package <span class="pkg">MASS</span> with no tuning parameters
</p>
<p><strong>Quadratic Discriminant Analysis with Stepwise Feature Selection</strong> (<code>method = 'stepQDA'</code>)
</p>
<p>For classification using packages <span class="pkg">klaR</span> and <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Number of Variables (<code>maxvar</code>, numeric)
</p>
</li>
<li><p> Search Direction (<code>direction</code>, character)
</p>
</li></ul>

<p><strong>Quantile Random Forest</strong> (<code>method = 'qrf'</code>)
</p>
<p>For regression using package <span class="pkg">quantregForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Quantile Regression Neural Network</strong> (<code>method = 'qrnn'</code>)
</p>
<p>For regression using package <span class="pkg">qrnn</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>n.hidden</code>, numeric)
</p>
</li>
<li><p>  Weight Decay (<code>penalty</code>, numeric)
</p>
</li>
<li><p> Bagged Models? (<code>bag</code>, logical)
</p>
</li></ul>

<p><strong>Quantile Regression with LASSO penalty</strong> (<code>method = 'rqlasso'</code>)
</p>
<p>For regression using package <span class="pkg">rqPen</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Radial Basis Function Kernel Regularized Least Squares</strong> (<code>method = 'krlsRadial'</code>)
</p>
<p>For regression using packages <span class="pkg">KRLS</span> and <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Radial Basis Function Network</strong> (<code>method = 'rbf'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Hidden Units (<code>size</code>, numeric)
</p>
</li></ul>

<p><strong>Radial Basis Function Network</strong> (<code>method = 'rbfDDA'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RSNNS</span> with tuning parameters:
</p>

<ul>
<li><p> Activation Limit for Conflicting Classes (<code>negativeThreshold</code>, numeric)
</p>
</li></ul>

<p><strong>Random Ferns</strong> (<code>method = 'rFerns'</code>)
</p>
<p>For classification using package <span class="pkg">rFerns</span> with tuning parameters:
</p>

<ul>
<li><p> Fern Depth (<code>depth</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest</strong> (<code>method = 'ranger'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">e1071</span> and <span class="pkg">ranger</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest</strong> (<code>method = 'Rborist'</code>)
</p>
<p>For classification and regression using package <span class="pkg">Rborist</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>predFixed</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest</strong> (<code>method = 'rf'</code>)
</p>
<p>For classification and regression using package <span class="pkg">randomForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest by Randomization</strong> (<code>method = 'extraTrees'</code>)
</p>
<p>For classification and regression using package <span class="pkg">extraTrees</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Number of  Random Cuts (<code>numRandomCuts</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest Rule-Based Model</strong> (<code>method = 'rfRules'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">randomForest</span>, <span class="pkg">inTrees</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Maximum Rule Depth (<code>maxdepth</code>, numeric)
</p>
</li></ul>

<p><strong>Random Forest with Additional Feature Selection</strong> (<code>method = 'Boruta'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">Boruta</span> and <span class="pkg">randomForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Discriminant Analysis</strong> (<code>method = 'rda'</code>)
</p>
<p>For classification using package <span class="pkg">klaR</span> with tuning parameters:
</p>

<ul>
<li><p> Gamma (<code>gamma</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Linear Discriminant Analysis</strong> (<code>method = 'rlda'</code>)
</p>
<p>For classification using package <span class="pkg">sparsediscrim</span> with tuning parameters:
</p>

<ul>
<li><p> Regularization Method (<code>estimator</code>, character)
</p>
</li></ul>

<p><strong>Regularized Random Forest</strong> (<code>method = 'RRF'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">randomForest</span> and <span class="pkg">RRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Regularization Value (<code>coefReg</code>, numeric)
</p>
</li>
<li><p> Importance Coefficient (<code>coefImp</code>, numeric)
</p>
</li></ul>

<p><strong>Regularized Random Forest</strong> (<code>method = 'RRFglobal'</code>)
</p>
<p>For classification and regression using package <span class="pkg">RRF</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li>
<li><p> Regularization Value (<code>coefReg</code>, numeric)
</p>
</li></ul>

<p><strong>Relaxed Lasso</strong> (<code>method = 'relaxo'</code>)
</p>
<p>For regression using packages <span class="pkg">relaxo</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Penalty Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Relaxation Parameter (<code>phi</code>, numeric)
</p>
</li></ul>

<p><strong>Relevance Vector Machines with Linear Kernel</strong> (<code>method = 'rvmLinear'</code>)
</p>
<p>For regression using package <span class="pkg">kernlab</span> with no tuning parameters
</p>
<p><strong>Relevance Vector Machines with Polynomial Kernel</strong> (<code>method = 'rvmPoly'</code>)
</p>
<p>For regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li></ul>

<p><strong>Relevance Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'rvmRadial'</code>)
</p>
<p>For regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li></ul>

<p><strong>Ridge Regression</strong> (<code>method = 'ridge'</code>)
</p>
<p>For regression using package <span class="pkg">elasticnet</span> with tuning parameters:
</p>

<ul>
<li><p> Weight Decay (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Ridge Regression with Variable Selection</strong> (<code>method = 'foba'</code>)
</p>
<p>For regression using package <span class="pkg">foba</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variables Retained (<code>k</code>, numeric)
</p>
</li>
<li><p> L2 Penalty (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Robust Linear Discriminant Analysis</strong> (<code>method = 'Linda'</code>)
</p>
<p>For classification using package <span class="pkg">rrcov</span> with no tuning parameters
</p>
<p><strong>Robust Linear Model</strong> (<code>method = 'rlm'</code>)
</p>
<p>For regression using package <span class="pkg">MASS</span> with tuning parameters:
</p>

<ul>
<li><p> intercept (<code>intercept</code>, logical)
</p>
</li>
<li><p> psi (<code>psi</code>, character)
</p>
</li></ul>

<p><strong>Robust Mixture Discriminant Analysis</strong> (<code>method = 'rmda'</code>)
</p>
<p>For classification using package <span class="pkg">robustDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Subclasses Per Class (<code>K</code>, numeric)
</p>
</li>
<li><p> Model (<code>model</code>, character)
</p>
</li></ul>

<p><strong>Robust Quadratic Discriminant Analysis</strong> (<code>method = 'QdaCov'</code>)
</p>
<p>For classification using package <span class="pkg">rrcov</span> with no tuning parameters
</p>
<p><strong>Robust Regularized Linear Discriminant Analysis</strong> (<code>method = 'rrlda'</code>)
</p>
<p>For classification using package <span class="pkg">rrlda</span> with tuning parameters:
</p>

<ul>
<li><p> Penalty Parameter (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Robustness Parameter (<code>hp</code>, numeric)
</p>
</li>
<li><p> Penalty Type (<code>penalty</code>, character)
</p>
</li></ul>

<p><strong>Robust SIMCA</strong> (<code>method = 'RSimca'</code>)
</p>
<p>For classification using package <span class="pkg">rrcovHD</span> with no tuning parameters
</p>
<p><strong>ROC-Based Classifier</strong> (<code>method = 'rocc'</code>)
</p>
<p>For classification using package <span class="pkg">rocc</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variables Retained (<code>xgenes</code>, numeric)
</p>
</li></ul>

<p><strong>Rotation Forest</strong> (<code>method = 'rotationForest'</code>)
</p>
<p>For classification using package <span class="pkg">rotationForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variable Subsets (<code>K</code>, numeric)
</p>
</li>
<li><p> Ensemble Size (<code>L</code>, numeric)
</p>
</li></ul>

<p><strong>Rotation Forest</strong> (<code>method = 'rotationForestCp'</code>)
</p>
<p>For classification using packages <span class="pkg">rpart</span>, <span class="pkg">plyr</span> and <span class="pkg">rotationForest</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Variable Subsets (<code>K</code>, numeric)
</p>
</li>
<li><p> Ensemble Size (<code>L</code>, numeric)
</p>
</li>
<li><p> Complexity Parameter (<code>cp</code>, numeric)
</p>
</li></ul>

<p><strong>Rule-Based Classifier</strong> (<code>method = 'JRip'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Optimizations (<code>NumOpt</code>, numeric)
</p>
</li></ul>

<p><strong>Rule-Based Classifier</strong> (<code>method = 'PART'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with tuning parameters:
</p>

<ul>
<li><p> Confidence Threshold (<code>threshold</code>, numeric)
</p>
</li>
<li><p> Confidence Threshold (<code>pruned</code>, character)
</p>
</li></ul>

<p><strong>Self-Organizing Map</strong> (<code>method = 'bdk'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kohonen</span> with tuning parameters:
</p>

<ul>
<li><p> Row (<code>xdim</code>, numeric)
</p>
</li>
<li><p> Columns (<code>ydim</code>, numeric)
</p>
</li>
<li><p> X Weight (<code>xweight</code>, numeric)
</p>
</li>
<li><p> Topology (<code>topo</code>, character)
</p>
</li></ul>

<p><strong>Self-Organizing Maps</strong> (<code>method = 'xyf'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kohonen</span> with tuning parameters:
</p>

<ul>
<li><p> Row (<code>xdim</code>, numeric)
</p>
</li>
<li><p> Columns (<code>ydim</code>, numeric)
</p>
</li>
<li><p> X Weight (<code>xweight</code>, numeric)
</p>
</li>
<li><p> Topology (<code>topo</code>, character)
</p>
</li></ul>

<p><strong>Semi-Naive Structure Learner Wrapper</strong> (<code>method = 'nbSearch'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Folds (<code>k</code>, numeric)
</p>
</li>
<li><p> Minimum Absolute Improvement (<code>epsilon</code>, numeric)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li>
<li><p> Final Smoothing Parameter (<code>final_smooth</code>, numeric)
</p>
</li>
<li><p> Search Direction (<code>direction</code>, character)
</p>
</li></ul>

<p><strong>Shrinkage Discriminant Analysis</strong> (<code>method = 'sda'</code>)
</p>
<p>For classification using package <span class="pkg">sda</span> with tuning parameters:
</p>

<ul>
<li><p> Diagonalize (<code>diagonal</code>, logical)
</p>
</li>
<li><p> shrinkage (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>SIMCA</strong> (<code>method = 'CSimca'</code>)
</p>
<p>For classification using package <span class="pkg">rrcovHD</span> with no tuning parameters
</p>
<p><strong>Simplified TSK Fuzzy Rules</strong> (<code>method = 'FS.HGD'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Max. Iterations (<code>max.iter</code>, numeric)
</p>
</li></ul>

<p><strong>Single C5.0 Ruleset</strong> (<code>method = 'C5.0Rules'</code>)
</p>
<p>For classification using package <span class="pkg">C50</span> with no tuning parameters
</p>
<p><strong>Single C5.0 Tree</strong> (<code>method = 'C5.0Tree'</code>)
</p>
<p>For classification using package <span class="pkg">C50</span> with no tuning parameters
</p>
<p><strong>Single Rule Classification</strong> (<code>method = 'OneR'</code>)
</p>
<p>For classification using package <span class="pkg">RWeka</span> with no tuning parameters
</p>
<p><strong>Sparse Distance Weighted Discrimination</strong> (<code>method = 'sdwd'</code>)
</p>
<p>For classification using package <span class="pkg">sdwd</span> with tuning parameters:
</p>

<ul>
<li><p> L1 Penalty (<code>lambda</code>, numeric)
</p>
</li>
<li><p> L2 Penalty (<code>lambda2</code>, numeric)
</p>
</li></ul>

<p><strong>Sparse Linear Discriminant Analysis</strong> (<code>method = 'sparseLDA'</code>)
</p>
<p>For classification using package <span class="pkg">sparseLDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Predictors (<code>NumVars</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Sparse Mixture Discriminant Analysis</strong> (<code>method = 'smda'</code>)
</p>
<p>For classification using package <span class="pkg">sparseLDA</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Predictors (<code>NumVars</code>, numeric)
</p>
</li>
<li><p> Lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Number of  Subclasses (<code>R</code>, numeric)
</p>
</li></ul>

<p><strong>Sparse Partial Least Squares</strong> (<code>method = 'spls'</code>)
</p>
<p>For classification and regression using package <span class="pkg">spls</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Components (<code>K</code>, numeric)
</p>
</li>
<li><p> Threshold (<code>eta</code>, numeric)
</p>
</li>
<li><p> Kappa (<code>kappa</code>, numeric)
</p>
</li></ul>

<p><strong>Spike and Slab Regression</strong> (<code>method = 'spikeslab'</code>)
</p>
<p>For regression using packages <span class="pkg">spikeslab</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Variables Retained (<code>vars</code>, numeric)
</p>
</li></ul>

<p><strong>Stabilized Linear Discriminant Analysis</strong> (<code>method = 'slda'</code>)
</p>
<p>For classification using package <span class="pkg">ipred</span> with no tuning parameters
</p>
<p><strong>Stabilized Nearest Neighbor Classifier</strong> (<code>method = 'snn'</code>)
</p>
<p>For classification using package <span class="pkg">snn</span> with tuning parameters:
</p>

<ul>
<li><p> Stabilization Parameter (<code>lambda</code>, numeric)
</p>
</li></ul>

<p><strong>Stacked AutoEncoder Deep Neural Network</strong> (<code>method = 'dnn'</code>)
</p>
<p>For classification and regression using package <span class="pkg">deepnet</span> with tuning parameters:
</p>

<ul>
<li><p> Hidden Layer 1 (<code>layer1</code>, numeric)
</p>
</li>
<li><p> Hidden Layer 2 (<code>layer2</code>, numeric)
</p>
</li>
<li><p> Hidden Layer 3 (<code>layer3</code>, numeric)
</p>
</li>
<li><p> Hidden Dropouts (<code>hidden_dropout</code>, numeric)
</p>
</li>
<li><p> Visible Dropout (<code>visible_dropout</code>, numeric)
</p>
</li></ul>

<p><strong>Stepwise Diagonal Linear Discriminant Analysis</strong> (<code>method = 'sddaLDA'</code>)
</p>
<p>For classification using package <span class="pkg">SDDA</span> with no tuning parameters
</p>
<p><strong>Stepwise Diagonal Quadratic Discriminant Analysis</strong> (<code>method = 'sddaQDA'</code>)
</p>
<p>For classification using package <span class="pkg">SDDA</span> with no tuning parameters
</p>
<p><strong>Stochastic Gradient Boosting</strong> (<code>method = 'gbm'</code>)
</p>
<p>For classification and regression using packages <span class="pkg">gbm</span> and <span class="pkg">plyr</span> with tuning parameters:
</p>

<ul>
<li><p> Number of  Boosting Iterations (<code>n.trees</code>, numeric)
</p>
</li>
<li><p> Max Tree Depth (<code>interaction.depth</code>, numeric)
</p>
</li>
<li><p> Shrinkage (<code>shrinkage</code>, numeric)
</p>
</li>
<li><p> Min. Terminal Node Size (<code>n.minobsinnode</code>, numeric)
</p>
</li></ul>

<p><strong>Subtractive Clustering and Fuzzy c-Means Rules</strong> (<code>method = 'SBC'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Radius (<code>r.a</code>, numeric)
</p>
</li>
<li><p> Upper Threshold (<code>eps.high</code>, numeric)
</p>
</li>
<li><p> Lower Threshold (<code>eps.low</code>, numeric)
</p>
</li></ul>

<p><strong>Supervised Principal Component Analysis</strong> (<code>method = 'superpc'</code>)
</p>
<p>For regression using package <span class="pkg">superpc</span> with tuning parameters:
</p>

<ul>
<li><p> Threshold (<code>threshold</code>, numeric)
</p>
</li>
<li><p> Number of Components (<code>n.components</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Boundrange String Kernel</strong> (<code>method = 'svmBoundrangeString'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> length (<code>length</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Class Weights</strong> (<code>method = 'svmRadialWeights'</code>)
</p>
<p>For classification using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li>
<li><p> Weight (<code>Weight</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Exponential String Kernel</strong> (<code>method = 'svmExpoString'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> lambda (<code>lambda</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Linear Kernel</strong> (<code>method = 'svmLinear'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Linear Kernel</strong> (<code>method = 'svmLinear2'</code>)
</p>
<p>For classification and regression using package <span class="pkg">e1071</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>cost</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Polynomial Kernel</strong> (<code>method = 'svmPoly'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Polynomial Degree (<code>degree</code>, numeric)
</p>
</li>
<li><p> Scale (<code>scale</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'svmRadial'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'svmRadialCost'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Radial Basis Function Kernel</strong> (<code>method = 'svmRadialSigma'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> Sigma (<code>sigma</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>Support Vector Machines with Spectrum String Kernel</strong> (<code>method = 'svmSpectrumString'</code>)
</p>
<p>For classification and regression using package <span class="pkg">kernlab</span> with tuning parameters:
</p>

<ul>
<li><p> length (<code>length</code>, numeric)
</p>
</li>
<li><p> Cost (<code>C</code>, numeric)
</p>
</li></ul>

<p><strong>The Bayesian lasso</strong> (<code>method = 'blasso'</code>)
</p>
<p>For regression using package <span class="pkg">monomvn</span> with tuning parameters:
</p>

<ul>
<li><p> Sparsity Threshold (<code>sparsity</code>, numeric)
</p>
</li></ul>

<p><strong>The lasso</strong> (<code>method = 'lasso'</code>)
</p>
<p>For regression using package <span class="pkg">elasticnet</span> with tuning parameters:
</p>

<ul>
<li><p> Fraction of Full Solution (<code>fraction</code>, numeric)
</p>
</li></ul>

<p><strong>Tree Augmented Naive Bayes Classifier</strong> (<code>method = 'tan'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Score Function (<code>score</code>, character)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Tree Augmented Naive Bayes Classifier Structure Learner Wrapper</strong> (<code>method = 'tanSearch'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Folds (<code>k</code>, numeric)
</p>
</li>
<li><p> Minimum Absolute Improvement (<code>epsilon</code>, numeric)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li>
<li><p> Final Smoothing Parameter (<code>final_smooth</code>, numeric)
</p>
</li>
<li><p> Super-Parent (<code>sp</code>, logical)
</p>
</li></ul>

<p><strong>Tree Augmented Naive Bayes Classifier with Attribute Weighting</strong> (<code>method = 'awtan'</code>)
</p>
<p>For classification using package <span class="pkg">bnclassify</span> with tuning parameters:
</p>

<ul>
<li><p> Score Function (<code>score</code>, character)
</p>
</li>
<li><p> Smoothing Parameter (<code>smooth</code>, numeric)
</p>
</li></ul>

<p><strong>Tree Models from Genetic Algorithms</strong> (<code>method = 'evtree'</code>)
</p>
<p>For classification and regression using package <span class="pkg">evtree</span> with tuning parameters:
</p>

<ul>
<li><p> Complexity Parameter (<code>alpha</code>, numeric)
</p>
</li></ul>

<p><strong>Tree-Based Ensembles</strong> (<code>method = 'nodeHarvest'</code>)
</p>
<p>For classification and regression using package <span class="pkg">nodeHarvest</span> with tuning parameters:
</p>

<ul>
<li><p> Maximum Interaction Depth (<code>maxinter</code>, numeric)
</p>
</li>
<li><p> Prediction Mode (<code>mode</code>, character)
</p>
</li></ul>

<p><strong>Variational Bayesian Multinomial Probit Regression</strong> (<code>method = 'vbmpRadial'</code>)
</p>
<p>For classification using package <span class="pkg">vbmp</span> with tuning parameters:
</p>

<ul>
<li><p> Theta Estimated (<code>estimateTheta</code>, character)
</p>
</li></ul>

<p><strong>Wang and Mendel Fuzzy Rules</strong> (<code>method = 'WM'</code>)
</p>
<p>For regression using package <span class="pkg">frbs</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Fuzzy Terms (<code>num.labels</code>, numeric)
</p>
</li>
<li><p> Membership Function (<code>type.mf</code>, character)
</p>
</li></ul>

<p><strong>Weighted Subspace Random Forest</strong> (<code>method = 'wsrf'</code>)
</p>
<p>For classification using package <span class="pkg">wsrf</span> with tuning parameters:
</p>

<ul>
<li><p> Number of Randomly Selected Predictors (<code>mtry</code>, numeric)
</p>
</li></ul>



<h3>References</h3>

<p>&ldquo;Using your own model in <code><a href="train.html">train</a></code>&rdquo; (<a href="http://caret.r-forge.r-project.org/custom_models.html">http://caret.r-forge.r-project.org/custom_models.html</a>)</p>

<hr /><div style="text-align: center;">[Package <em>caret</em> version 6.0-71 <a href="00Index.html">Index</a>]</div>
</body></html>
