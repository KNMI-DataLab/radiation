<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Optimal Weighted Nearest Neighbor Classification</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for ownn {FNN}"><tr><td>ownn {FNN}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>
Optimal Weighted Nearest Neighbor Classification
</h2>

<h3>Description</h3>

<p>This function implements Samworth's optimal weighting scheme for k nearest neighbor classification. The performance improvement is greatest when the dimension is 4 as reported in the reference.
</p>


<h3>Usage</h3>

<pre>
  ownn(train, test, cl, testcl=NULL, k = NULL, prob = FALSE,
      algorithm=c("kd_tree", "cover_tree", "brute"))
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>train</code></td>
<td>
<p>matrix or data frame of training set cases.</p>
</td></tr>
<tr valign="top"><td><code>test</code></td>
<td>
<p>matrix or data frame of test set cases. A vector will be interpreted
as a row vector for a single case.</p>
</td></tr>
<tr valign="top"><td><code>cl</code></td>
<td>
<p>factor of true classifications of training set.</p>
</td></tr>
<tr valign="top"><td><code>testcl</code></td>
<td>
<p>factor of true classifications of testing set for error rate calculation.</p>
</td></tr>
<tr valign="top"><td><code>k</code></td>
<td>
<p>number of neighbours considered, chosen by 5-fold cross-validation if not supplied.</p>
</td></tr>
<tr valign="top"><td><code>prob</code></td>
<td>
<p>if this is true, the proportion of the weights for the winning class
are returned as attribute <code>prob</code>.</p>
</td></tr>
<tr valign="top"><td><code>algorithm</code></td>
<td>
<p>nearest neighbor search algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list includes k, predictions by ordinary knn, optimal weighted knn and bagged knn, and accuracies if class labels of test data set are given. 
</p>


<h3>Author(s)</h3>

<p>Shengqiao Li. To report any bugs or suggestions please email: <a href="mailto:shli@stat.wvu.edu.">shli@stat.wvu.edu.</a></p>


<h3>References</h3>

<p>Richard J. Samworth (2012),
&ldquo;Optimal Weighted Nearest Neighbor Classifiers,&rdquo; <em>Annals of Statistics</em>,  <b>40:5</b>, 2733-2763.
</p>


<h3>See Also</h3>

<p><code><a href="knn.html">knn</a></code> and <code><a href="../../class/html/knn.html">knn</a></code> in <span class="pkg">class</span>.
</p>


<h3>Examples</h3>

<pre>
    data(iris3)
    train &lt;- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
    test &lt;- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
    cl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
    testcl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
    out &lt;- ownn(train, test, cl, testcl)
    out
</pre>

<hr /><div style="text-align: center;">[Package <em>FNN</em> version 1.1 <a href="00Index.html">Index</a>]</div>
</body></html>
