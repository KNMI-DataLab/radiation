<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Model-based Gradient Boosting</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for mboost {mboost}"><tr><td>mboost {mboost}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2> Model-based Gradient Boosting </h2>

<h3>Description</h3>

<p>Gradient boosting for optimizing arbitrary loss functions, where component-wise
models are utilized as base-learners.
</p>


<h3>Usage</h3>

<pre>
mboost(formula, data = list(), na.action = na.omit,
       baselearner = c("bbs", "bols", "btree", "bss", "bns"), ...)
mboost_fit(blg, response, weights = rep(1, NROW(response)), offset = NULL,
           family = Gaussian(), control = boost_control(), oobweights =
           as.numeric(weights == 0))
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>formula</code></td>
<td>
<p> a symbolic description of the model to be fit. </p>
</td></tr>
<tr valign="top"><td><code>data</code></td>
<td>
<p> a data frame containing the variables in the model. </p>
</td></tr>
<tr valign="top"><td><code>na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.</p>
</td></tr>
<tr valign="top"><td><code>baselearner</code></td>
<td>
<p> a character specifying the component-wise base
learner to be used: <code><a href="baselearners.html">bbs</a></code> means P-splines with a
B-spline basis (see Schmid and Hothorn 2008), <code><a href="baselearners.html">bols</a></code>
linear models and <code><a href="baselearners.html">btree</a></code> boosts stumps.
<code>bss</code> and <code>bns</code> are deprecated.
Component-wise smoothing splines have been considered in Buehlmann
and Yu (2003) and Schmid and Hothorn (2008) investigate P-splines
with a B-spline basis. Kneib, Hothorn and Tutz (2009) also utilize
P-splines with a B-spline basis, supplement them with their
bivariate tensor product version to estimate interaction surfaces
and spatial effects and also consider random effects base
learners.</p>
</td></tr>
<tr valign="top"><td><code>blg</code></td>
<td>
<p> a list of objects of class <code>blg</code>, as returned by all
base-learners.</p>
</td></tr>
<tr valign="top"><td><code>response</code></td>
<td>
<p> the response variable.</p>
</td></tr>
<tr valign="top"><td><code>weights</code></td>
<td>
<p> a numeric vector of weights (optional).</p>
</td></tr>
<tr valign="top"><td><code>offset</code></td>
<td>
<p> a numeric vector to be used as offset (optional).</p>
</td></tr>
<tr valign="top"><td><code>family</code></td>
<td>
<p>a <code><a href="Family.html">Family</a></code> object.</p>
</td></tr>
<tr valign="top"><td><code>control</code></td>
<td>
<p> a list of parameters controlling the algorithm. For
more details see <code><a href="control.html">boost_control</a></code>. </p>
</td></tr>
<tr valign="top"><td><code>oobweights</code></td>
<td>
<p> an additional vector of out-of-bag weights, which is
used for the out-of-bag risk (i.e., if <code>boost_control(risk =
      "oobag")</code>). This argument is also used internally by
<code>cvrisk</code>. </p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>  additional arguments passed to <code><a href="mboost.html">mboost_fit</a></code>,
including <code>weights</code>, <code>offset</code>, <code>family</code> and
<code>control</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements component-wise functional gradient boosting in
a generic way. Basically, the algorithm is initialized with a function
for computing the negative gradient of the loss function (via its
<code>family</code> argument) and one or more base-learners (given as
<code>blg</code>). Usually <code>blg</code> and <code>response</code> are computed in
the functions <code><a href="gamboost.html">gamboost</a></code>, <code><a href="glmboost.html">glmboost</a></code>,
<code><a href="blackboost.html">blackboost</a></code> or <code>mboost</code>.
</p>
<p>The algorithm minimized the in-sample empirical risk defined as
the weighted sum (by <code>weights</code>) of the loss function (corresponding
to the negative gradient) evaluated at the data.
</p>
<p>The structure of the model is determined by the structure
of the base-learners. If more than one base-learner is given,
the model is additive in these components.
</p>
<p>Base-learners can be specified via a formula interface
(function <code>mboost</code>) or as a list of objects of class <code>bl</code>,
see <code><a href="baselearners.html">bols</a></code>.
</p>
<p><code>oobweights</code> is a vector used internally by <code>cvrisk</code>. When carrying
out cross-validation to determine the optimal stopping iteration of a boosting
model, the default value of <code>oobweights</code> (out-of-bag weights) assures
that the cross-validated risk is computed using the same observation weights
as those used for fitting the boosting model. It is strongly recommended to
leave this argument unspecified.
</p>
<p>Note that the more convenient modelling interfaces <code><a href="gamboost.html">gamboost</a></code>,
<code><a href="glmboost.html">glmboost</a></code> and <code><a href="blackboost.html">blackboost</a></code> all call
<code>mboost</code> directly.
</p>


<h3>Value</h3>

<p>An object of class <code>mboost</code> with <code><a href="../../base/html/print.html">print</a></code>,
<code><a href="../../stats/html/AIC.html">AIC</a></code>, <code><a href="plot.html">plot</a></code> and <code><a href="../../stats/html/predict.html">predict</a></code>
methods being available.
</p>


<h3>References</h3>

<p>Peter Buehlmann and Bin Yu (2003),
Boosting with the L2 loss: regression and classification.
<em>Journal of the American Statistical Association</em>, <b>98</b>,
324&ndash;339.
</p>
<p>Peter Buehlmann and Torsten Hothorn (2007),
Boosting algorithms: regularization, prediction and model fitting.
<em>Statistical Science</em>, <b>22</b>(4), 477&ndash;505.
</p>
<p>Torsten Hothorn, Peter Buehlmann, Thomas Kneib, Mattthias Schmid and
Benjamin Hofner (2010), Model-based Boosting 2.0. <em>Journal of
Machine Learning Research</em>, <b>11</b>, 2109&ndash;2113.
</p>
<p>Yoav Freund and Robert E. Schapire (1996),
Experiments with a new boosting algorithm.
In <em>Machine Learning: Proc. Thirteenth International Conference</em>,
148&ndash;156.
</p>
<p>Jerome H. Friedman (2001),
Greedy function approximation: A gradient boosting machine.
<em>The Annals of Statistics</em>, <b>29</b>, 1189&ndash;1232.
</p>
<p>Benjamin Hofner, Andreas Mayr, Nikolay Robinzonov and Matthias Schmid
(2014). Model-based Boosting in R: A Hands-on Tutorial Using the R
Package mboost. <em>Computational Statistics</em>, <b>29</b>, 3&ndash;35.<br />
<a href="http://dx.doi.org/10.1007/s00180-012-0382-5">http://dx.doi.org/10.1007/s00180-012-0382-5</a>
</p>
<p>Available as vignette via: <code>vignette(package = "mboost", "mboost_tutorial")</code>
</p>


<h3>See Also</h3>

<p><code><a href="glmboost.html">glmboost</a></code> for boosted linear models and
<code><a href="blackboost.html">blackboost</a></code> for boosted trees. See e.g. <code><a href="baselearners.html">bbs</a></code>
for possible base-learners. See <code><a href="cvrisk.html">cvrisk</a></code> for
cross-validated stopping iteration. Furthermore see
<code><a href="control.html">boost_control</a></code>, <code><a href="Family.html">Family</a></code> and
<code><a href="methods.html">methods</a></code>. </p>


<h3>Examples</h3>

<pre>
  data("bodyfat", package = "TH.data")

  ### formula interface: additive Gaussian model with
  ### a non-linear step-function in `age', a linear function in `waistcirc'
  ### and a smooth non-linear smooth function in `hipcirc'
  mod &lt;- mboost(DEXfat ~ btree(age) + bols(waistcirc) + bbs(hipcirc),
                data = bodyfat)
  layout(matrix(1:6, nc = 3, byrow = TRUE))
  plot(mod, main = "formula")

  ### the same
  with(bodyfat,
       mod &lt;- mboost_fit(list(btree(age), bols(waistcirc), bbs(hipcirc)),
                         response = DEXfat))
  plot(mod, main = "base-learner")
</pre>

<hr /><div style="text-align: center;">[Package <em>mboost</em> version 2.6-0 <a href="00Index.html">Index</a>]</div>
</body></html>
