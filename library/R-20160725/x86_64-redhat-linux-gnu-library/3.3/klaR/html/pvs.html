<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Pairwise variable selection for classification</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for pvs {klaR}"><tr><td>pvs {klaR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Pairwise variable selection for classification</h2>

<h3>Description</h3>

<p>Pairwise variable selection for numerical data, allowing the use of different classifiers and different variable selection methods.
</p>


<h3>Usage</h3>

<pre>
pvs(x, ...)

## Default S3 method:
pvs(x, grouping, prior=NULL, method="lda", 
    vs.method=c("ks.test","stepclass","greedy.wilks"), niveau=0.05, 
    fold=10, impr=0.1, direct="backward", out=FALSE, ...)
    
## S3 method for class 'formula'
pvs(formula, data = NULL, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>matrix or data frame containing the explanatory variables 
(required, if <code>formula</code> is not given). x must consist of numerical data only. </p>
</td></tr>
<tr valign="top"><td><code>formula</code></td>
<td>
<p>A formula of the form <code>groups ~ x1 + x2 + ...</code>. 
That is, the response is the grouping factor (the classes) and the right hand side 
specifies the (numerical) discriminators. 
Interaction terms are not supported.</p>
</td></tr>
<tr valign="top"><td><code>data</code></td>
<td>
<p>data matrix (rows=cases, columns=variables)</p>
</td></tr>
<tr valign="top"><td><code>grouping</code></td>
<td>
<p>class indicator vector (a factor)</p>
</td></tr>
<tr valign="top"><td><code>prior</code></td>
<td>
<p>prior probabilites for the classes. If not specified the prior probabilities will be set according to proportion in &ldquo;grouping&rdquo;. If specified the order of prior 
probabilities must be the same as in &ldquo;grouping&rdquo;. </p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>character, name of classification function (e.g. &ldquo;<code><a href="../../MASS/html/lda.html">lda</a></code>&rdquo; (default)).</p>
</td></tr>
<tr valign="top"><td><code>vs.method</code></td>
<td>
<p>character, name of variable selection method. Must be one of &ldquo;<code><a href="../../stats/html/ks.test.html">ks.test</a></code>&rdquo; (default),
&ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; or &ldquo;<code><a href="greedy.wilks.html">greedy.wilks</a></code>&rdquo;. </p>
</td></tr>
<tr valign="top"><td><code>niveau</code></td>
<td>
<p>used niveau for &ldquo;<code><a href="../../stats/html/ks.test.html">ks.test</a></code>&rdquo;</p>
</td></tr>
<tr valign="top"><td><code>fold</code></td>
<td>
<p>parameter for cross-validation, if &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; is chosen &lsquo;<code>vs.method</code>&rsquo;</p>
</td></tr>                                            
<tr valign="top"><td><code>impr</code></td>
<td>
<p>least improvement of performance measure desired to include or exclude any variable (&lt;=1), if &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; is chosen &lsquo;<code>vs.method</code>&rsquo; </p>
</td></tr>  
<tr valign="top"><td><code>direct</code></td>
<td>
<p>direction of variable selection, if &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; is chosen &lsquo;<code>vs.method</code>&rsquo;. 
Must be one if &ldquo;<code>forward</code>&rdquo;, &ldquo;<code>backward</code>&rdquo; (default) or &ldquo;<code>both</code>&rdquo;. </p>
</td></tr>
<tr valign="top"><td><code>out</code></td>
<td>
<p>indicator (logical) for textoutput during computation (slows down computation!), if &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; is chosen &lsquo;<code>vs.method</code>&rsquo; </p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>further parameters passed to classification function (&lsquo;<code>method</code>&rsquo;) or variable selection method (&lsquo;<code>vs.method</code>&rsquo;) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classification &ldquo;method&rdquo; (e.g. &lsquo;<code><a href="../../MASS/html/lda.html">lda</a></code>&rsquo;) must have its own 
&lsquo;<code>predict</code>&rsquo; method (like &lsquo;<code><a href="../../MASS/html/predict.lda.html">predict.lda</a></code>&rsquo; for &lsquo;<code>lda</code>&rsquo;) 
returns a list with an element &lsquo;<code>posterior</code>&rsquo; containing the posterior probabilties. It must be able to deal with matrices as in <code>method(x, grouping, ...)</code>. 
Examples of such classification methods are &lsquo;<code><a href="../../MASS/html/lda.html">lda</a></code>&rsquo;, &lsquo;<code><a href="../../MASS/html/qda.html">qda</a></code>&rsquo;, &lsquo;<code><a href="rda.html">rda</a></code>&rsquo;, 
&lsquo;<code><a href="NaiveBayes.html">NaiveBayes</a></code>&rsquo; or &lsquo;<code><a href="sknn.html">sknn</a></code>&rsquo;.\
For the classification methods &ldquo;<code><a href="../../e1071/html/svm.html">svm</a></code>&rdquo; and &ldquo;<code><a href="../../randomForest/html/randomForest.html">randomForest</a></code>&rdquo; there are special routines implemented, to make them work with &lsquo;<code>pvs</code>&rsquo; method even though their &lsquo;<code>predict</code>&rsquo; methods don't provide the demanded posteriors. However those two classfiers can not be used together with variable selection method &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo;.
</p>
<p>&lsquo;<code>pvs</code>&rsquo; performs a variable selection using the selection method chosen in &lsquo;<code>vs.method</code>&rsquo; for each pair of classes in &lsquo;<code>x</code>&rsquo;. 
Then for each pair of classes a submodel using &lsquo;<code>method</code>&rsquo; is trained (using only the earlier selected variables for this class-pair).
</p>
<p>If &lsquo;<code>method</code>&rsquo; is &ldquo;<code><a href="../../stats/html/ks.test.html">ks.test</a></code>&rdquo;, then for each variable the empirical distribution functions of the cases of both classes are compared via &ldquo;<code><a href="../../stats/html/ks.test.html">ks.test</a></code>&rdquo;. Only variables with a p-values below &lsquo;<code>niveau</code>&rsquo; are used for training the submodel for this pair of classes.
</p>
<p>If &lsquo;<code>method</code>&rsquo; is &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; the variable selection is performed using the &ldquo;<code><a href="stepclass.html">stepclass</a></code>&rdquo; method.
</p>
<p>If &lsquo;<code>method</code>&rsquo; is &ldquo;<code><a href="greedy.wilks.html">greedy.wilks</a></code>&rdquo; the variable selection is performed using Wilk's lambda criterion.
</p>


<h3>Value</h3>

<p>An object of class &lsquo;<code>pvs</code>&rsquo; containing the following components:
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>classes</code></td>
<td>
<p>the classes in grouping</p>
</td></tr>
<tr valign="top"><td><code>prior</code></td>
<td>
<p>used prior probabilities</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>name of used classification function</p>
</td></tr>
<tr valign="top"><td><code>vs.method</code></td>
<td>
<p>name of used function for variable selection</p>
</td></tr>
<tr valign="top"><td><code>submodels</code></td>
<td>
<p>containing a list of submodels. For each pair of classes there is a list element being another list of 3 containing the class-pair of this submodel, the selected variables 
for the subspace of classes and the result of the trained classification function.</p>
</td></tr>
<tr valign="top"><td><code>call</code></td>
<td>
<p>the (matched) function call</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gero Szepannek, <a href="mailto:szepannek@statistik.tu-dortmund.de">szepannek@statistik.tu-dortmund.de</a>, Christian Neumann</p>


<h3>References</h3>


<ul>
<li><p>Szepannek, G. and Weihs, C. (2006)  Variable Selection for Classification of More than Two 
Classes Where the Data are Sparse. In <em>From Data and Information Analysis to Kwnowledge Engineering.</em>,
eds Spiliopolou, M., Kruse, R., Borgelt, C., Nuernberger, A. and Gaul, W. pp. 700-708. Springer, Heidelberg.
</p>
</li>
<li><p>Szepannek, G. (2008): Different Subspace Classification - Datenanalyse, -interpretation, -visualisierung und 
Vorhersage in hochdimensionalen Raeumen, ISBN 978-3-8364-6302-7, vdm, Saarbruecken.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="predict.pvs.html">predict.pvs</a></code> for predicting &lsquo;<code>pvs</code>&rsquo; models and <code><a href="locpvs.html">locpvs</a></code> for pairwisevariable selection in local models of several subclasses
</p>


<h3>Examples</h3>

<pre>
## Example 1: learn an "lda" model on the waveform data using pairwise variable 
## selection (pvs) using "ks.test" and compare it to using lda without pvs 

library("mlbench")
trainset &lt;- mlbench.waveform(300) 
pvsmodel &lt;- pvs(trainset$x, trainset$classes, niveau=0.05) # default: using method="lda"
## short summary, showing the class-pairs of the submodels and the selected variables
pvsmodel
 
testset &lt;-  mlbench.waveform(500)
## prediction of the test data set: 
prediction &lt;- predict(pvsmodel, testset$x)

## calculating the test error rate
1-sum(testset$classes==prediction$class)/length(testset$classes)
## Bayes error is 0.149

## comparison to performance of simple lda
ldamodel &lt;- lda(trainset$x, trainset$classes)
LDAprediction &lt;- predict(ldamodel, testset$x)

## test error rate
1-sum(testset$classes==LDAprediction$class)/length(testset$classes)


## Example 2: learn a "qda" model with pvs on half of the Satellite dataset, 
## using "ks.test" 

library("mlbench")
data("Satellite")

model &lt;- pvs(classes ~ ., Satellite[1:3218,], method="qda", vs.method="ks.test")
## short summary, showing the class-pairs of the submodels and the selected variables
model 

## now predict on the rest of the data set:
## pred &lt;- predict(model,Satellite[3219:6435,]) # takes some time
pred &lt;- predict(model,Satellite[3219:6435,], quick=TRUE) # that's much quicker

## now you can look at the predicted classes:
pred$class 
## or the posterior probabilities:
pred$posterior
</pre>

<hr /><div style="text-align: center;">[Package <em>klaR</em> version 0.6-12 <a href="00Index.html">Index</a>]</div>
</body></html>
